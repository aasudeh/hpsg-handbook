\documentclass[output=paper
                ,modfonts
                ,nonflat
	        ,collection
	        ,collectionchapter
	        ,collectiontoclongg
 	        ,biblatex
                ,babelshorthands
                ,newtxmath
                ,draftmode
                ,colorlinks, citecolor=brown
]{./langsci/langscibook}

\IfFileExists{../localcommands.tex}{%hack to check whether this is being compiled as part of a collection or standalone
  \input{../localpackages}
  \input{../localcommands}
  \input{../localhyphenation}
  \bibliography{../Bibliographies/stmue,
                ../localbibliography,
../Bibliographies/formal-background,
../Bibliographies/understudied-languages,
../Bibliographies/phonology,
../Bibliographies/case,
../Bibliographies/evolution,
../Bibliographies/agreement,
../Bibliographies/lexicon,
../Bibliographies/np,
../Bibliographies/negation,
../Bibliographies/argst,
../Bibliographies/binding,
../Bibliographies/complex-predicates,
../Bibliographies/coordination,
../Bibliographies/relative-clauses,
../Bibliographies/udc,
../Bibliographies/processing,
../Bibliographies/cl,
../Bibliographies/dg,
../Bibliographies/islands,
../Bibliographies/diachronic,
../Bibliographies/gesture,
../Bibliographies/semantics,
../Bibliographies/pragmatics,
../Bibliographies/information-structure,
../Bibliographies/idioms,
../Bibliographies/cg,
../Bibliographies/udc}

  \togglepaper[34]
}{}



\author{Stephen Wechsler\affiliation{The University of Texas}
\and Ash Asudeh\affiliation{University of Rochester} }
\title{HPSG and Lexical Functional Grammar}

% \chapterDOI{} %will be filled in at production

\epigram{Here is the epigram:  more people have been to Berlin than I have}
\abstract{Here is the abstract: concrete gets you through abstract
better than abstract gets you through concrete}

%\bibliography{Bibliographies/wechsler,Bibliographies/jp2,Bibliographies/stmue}

\begin{document}
\maketitle

\section{Introduction} 
Head-Driven Phrase Structure Grammar is similar in many respects to its cousin framework, Lexical Functional Grammar or LFG \citep{BATW2015a,Dalrymple2001a-u}.  Both  HPSG and LFG are lexicalist frameworks in the sense that they distinguish between the morphological system which creates words, and the syntax proper which combines those fully inflected words into phrases and sentences.  Both frameworks assume a lexical theory of argument structure \citep{MWArgSt} in which verbs and other predicators come equipped with valence structures indicating the kinds of complements and other dependents that the word is to be combined with.  Both theories treat control (equi) and raising as a lexical property of certain control or raising predicates.  Both  representational systems  are based on unification grammar \citep{Kay84a-u}, employing directed graphs that are often represented in the form of recursively embedded feature structures.   Phonologically empty nodes of the constituent structure are avoided in both theories, with the gaps appearing in long-distance dependencies as the sole exception in some analyses, and complete elimination of empty categories even in those cases, in others.   

At the same time, there are interesting differences.  Each theory makes available certain representational resources that the other theory lacks.   LFG has output filters in the form of \textit{constraining equations}, HPSG does not.  HPSG's feature structures are \textit{typed}, those of LFG are not.  The feature descriptions (directed graphs) are fully integrated with the phrase structure grammar in the case of HPSG, while in LFG they are intentionally separated in an autonomous level of representation in the form of a \textit{functional structure} or f-structure.  These differences lead some linguists to feel that certain types of generalization are more perspicuously stated in one framework than the other.   Because LFG's functional structure is autonomous from the constituent structure whose terminal yield gives the order of words in a sentence, that functional structure can instead serve as a representation of the grammatical functions played by various components of a sentence.  This makes LFG more amenable to a functionalist motivation, and also provides a standard representation language for capturing the more cross-linguistically invariant properties of syntax.  Meanwhile, HPSG is more deeply rooted in phrase structure grammar, and thus provides a clearer representation of the locality conditions that are important for the proper functioning of grammars.  

This chapter presents a comparison of the two theories with an emphasis on contrasts between the two.  It is organized by grammatical topic.  


\section{Phrases and Endocentricity} 
A phrasal node shares certain grammatical features with specific daughters, such as the \textsc{head} features that it shares with the head daughter.  In HPSG this is accomplished
by means of structure-sharing (reentrancies) in the immediate dominance schemata and other 
constraints on local sub-trees such as the Head Feature Principle.  LFG employs essentially the same mechanism for feature sharing in a local sub-tree but implements it slightly differently.  Each node in a phrase structure is paired with a so-called functional structure or \textit{f-structure}, which is formally a set of attribute-value pairs.  It is through the f-structure that the nodes of the phrase structure share features.   The phrase structure is referred to as \textit{c-structure}, for categorial or constituent structure, in order to distinguish it from f-structure.  The grammar, in the form of a standard rewriting system, directly generates only c-structures, not f-structures.   Those c-structure rules introduce equations that form a projection function from c-structure to f-structure.  For example, the phrase structure grammar in \ref{psg} and lexicon in \ref{lex} generate the tree in \ref{tree1}.  

\eal  \label{psg}
\ex
{
\phraserule{S}{\rulenode{NP\\(\up \feat{subj})=\down}
               \rulenode{VP\\ \up=\down}}}

\ex 

{
\phraserule{NP}{\optrulenode{Det\\ \up=\down}
                \rulenode{N\\ \up=\down}}}

\ex 

{
\phraserule{VP}{\rulenode{V\\ \up=\down}
                \optrulenode{NP\\(\up \obj)=\down}}}

\zl

\eal \label{lex} 
\ex 

{
\makebox[4em][l]{{\it lion}\/: N}\qquad\feqs{(\up \pred) = `lion'\\
(\up \num) = \sg}}
%\makebox[4em][l]{-{\it s}\/: {\it infl}\/\pslabel{n}}\qquad\feqs{(\up \num) = \sg}

\ex 

{\label{indent}
\makebox[4em][l]{{\it rule}\/: V}\qquad\feqs{(\up \pred) = `rule$\leftangle
(\up \feat{subj})$'}

\makebox[4em][l]{-{\it s}\/: {\it infl}\/\pslabel{v}}\qquad\feqs{(\up \feat{tense}) = \feat{pres}\\
                  (\up \feat{subj}) = \down\\
                  \qquad(\down\ \feat{pers}) = 3\\
                  \qquad(\down\ \num) = \feat{sg}}}


\zl



%\begin{forest}
%sm edges
%[S 
%  [NP
%    [Det [those]]
%    [N   [lions]]]
%  [VP
%    [V   [rule]]]]
%\end{forest}

\eal 
 \label{tree1} { }
\zl
\begin{forest}
sm edges without translation
[S 
  [\csn{(\up\feat{subj}) $=$ \down}{DP}
    [\csn{\updown}{Det} [that\\
                         {(\up \feat{num}) $=$ \feat{plur}}\\
                         {(\up \feat{prox}) $=$ \feat{+}}]]
    [\csn{\updown}{N}   [lion\\
                         {(\up \feat{pred}) $=$ \feat{`lion'}}\\
                         {(\up \feat{num}) $=$ \feat{plur}}]]]
  [\csn{\updown}{VP}
    [\csn{\updown}{V}   [rule-s\\
                         {(\up \feat{pred}) $=$ `rule$\langle (\up\feat{subj}) \rangle $'}
                         \\ {(\up \feat{tense}) = \feat{pres}}\\
                  {(\up \feat{subj}) = \down}\\
                 {(\down\ \feat{pers}) = 3}\\
                  {(\down\ \num) = \feat{sg}} ]]]]
\end{forest}

\noindent
Each node in the c-structure maps to a function, that is, to a set of attribute-value pairs.  Within the equations, the up and down arrows are metavariables over function names, interpreted as follows:  the up arrow refers to the function to which the mother node maps, and the down arrow refers to the function that its own node maps to.  To derive the f-structure from \ref{tree1}, we instantiate the metavariables to specific function names and solve for the function associated with the root node (here, S).  In \ref{tree2} the function names \textit{f1, f2,} etc. are subscripted to the node labels.  The arrows have been replaced with those function names.  

\eal 
 \label{tree2} { }
\zl
\begin{forest}
sm edges without translation
[S$_{f1}$ 
  [\csn{(f1 \feat{subj}) $=$ f2}{DP$_{f2}$}
    [\csn{f2 = f4}{Det$_{f4}$} [that$_{f7}$\\
                         {(f4 \feat{num}) $=$ \feat{plur}}\\
                         {(f4 \feat{prox}) $=$ \feat{+}}]]
    [\csn{f2 = f5}{N$_{f5}$}   [lion$_{f8}$\\
                         {(f5 \feat{pred}) $=$ \feat{`lion'}}\\
                         {(f5 \feat{num}) $=$ \feat{sg}}]]]
  [\csn{f1 = f3}{VP$_{f3}$}
    [\csn{f3 = f6}{V$_{f6}$}   [rules$_{f9}$\\
                         {(f6 \feat{pred}) $=$ `rule$\langle (f6 \feat{subj}) \rangle $'}
                         \\ {(f6 \feat{tense}) = \feat{pres}}\\
                  {(f6 \feat{subj}) = f9}\\
                 {(f9\ \feat{pers}) = 3}\\
                  {(f9\ \num) = \feat{sg}} ]]]]
\end{forest}

\noindent
Collecting all the equations from this tree and solving for \textit{f1}, we arrive at the f-structure in \ref{fs1}:

\ea		
\label{fs1} 
{\avmoptions{center}
\begin{avm}
\[ subj &  \[ pred & `\textsc{lion}' \\ num & \textsc{sg} \\ pers & 3 \\ prox & + \] \\
pred & `rule$\langle (\up\feat{subj}) \rangle $' \\
tense & \textsc{pres} \]
\end{avm}
}
\z

\noindent
Since the up and down arrows refer to nodes of the local subtree, LFG annotated phrase structure rules like those in \ref{psg} can often be directly translated into HPSG immediate dominance schemata and principles constraining local subtrees.  
By way of illustration, let \textsc{fs} (for \textit{f-structure}) be an HPSG attribute corresponding to the f-structure projection function.  Then the LFG rule in \ref{psg2}a (repeated from \ref{psg}a above) is equivalent to the  HPSG rule in \ref{psg2}b:

\eal 
 \label{psg2}
\ex
{
\phraserule{S}{\rulenode{DP\\(\up \feat{subj})=\down}
               \rulenode{VP\\ \up=\down}}}
               
\ex 
{
\phraserule{S[\textsc{fs} \fbox{1}]}{\rulenode{DP[\textsc{fs} \fbox{2}]}  \rulenode{VP[\textsc{fs}  \fbox{1}[\textsc{subj} \fbox{2}]}}}
\zl

\noindent
Let us compare the two representations with respect to heads and dependents.

Taking heads first, the VP node annotated with \updown is an \textit{f-structure head}, meaning that the features of the VP are identified with those of the mother S.  This effect is equivalent to the tag \fbox{1} in \ref{psg2}b.    Hence  \updown has an effect similar to HPSG's Head Feature Principle.  However, in LFG the part of speech categories and their projections such as N, V, Det, NP, VP, DP, etc. belong to the c-structure and not the f-structure.  As a consequence those features are not subject to sharing, and any principled correlations between such categories, such as the fact that N is the head of NP, V the head of VP, C as head of CP, and so on, are instead captured in an explicit version of (extended) X-bar theory applying to the c-structure.  The  LFG based theory of endocentricity is considerably weaker (more permissive) than what is typically found in most transformation based grammars.  The version of extended X-bar theory in \cite[ch. ]{BATW2015a} assumes that all nodes on the right side of the arrow of the phrase structure rule are optional, with many unacceptable partial structures ruled out in the f-structure instead (see Section XXX below for well-formedness constraints on f-structures).  Also not all structures need to be endocentric (i.e. not all structures have a head daughter in c-structure).  The LFG category S shown in \ref{psg2}a is inherently exocentric, lacking a c-structure head, and is used for the analysis of copulaless clauses.   (English is also assumed to have endocentric clauses of category IP, where an auxiliary verb of category I (for Inflection) serves as the c-structure head.)  S is also used for flat structures in non-configurational clauses found in languages such as Warlpiri.   

Functional projections like DP, IP, and CP are typically assumed to form a `shell' over the lexical projections NP, VP, AP, and PP (plus CP can appear over S).  In fact this idea of extending X-bar to functional categories has its origin in the LFG work of the late Yehuda Falk (REFS), from which it then spread to  transformational theories.   This is formally implemented by having the functional head (such as Det) and its lexical complement (such as NP) be f-structure co-heads.  See for example the DP \textit{that lion} in \ref{tree1}, where Det and N are both annotated with \updown .  The DP, Det, and N nodes all map to the same f-structure, namely the subsidiary structure serving as the value of SUBJ (see \ref{fs1}).  What makes this unification possible is that function words lack a PRED (for `predicate') feature that would otherwise indicate a semantic form.  Content words such as \textit{lion} have such a feature ([\textsc{pred} `\textsc{lion}']), and so if the Det had one as well then they would clash in the f-structure.  Note more generally that the f-structure flattens out much of the hierarchical structure of the corresponding c-structure.  



Complementation works a little differently in LFG from HPSG.  Note that the LFG  rule \ref{psg2}a indicates the SUBJ grammatical function on the subject NP node, while the pseudo-HPSG rule \ref{psg2}b indicates the SUBJ function on the VP functor selecting the subject.   A consequence of the use of functional equations in LFG is that a grammatical relation such as SUBJ can be locally associated with its formal exponents, whether a configurational position in phrase structure (as in \ref{tree1}), head-marking (agreement), or dependent marking (case).  A subject-marking case affix can introduce a so-called `inside out' functional designator, (SUBJ \up), which requires that the f-structure of the DP bearing that case ending be the value of a SUBJ attribute REFS-NORDLINGER.\footnote{For function f, attribute a and value v, $(f \, a) = v$ iff $(a \, v) = f$.}  This aspect of LFG representations makes it convenient for functionalist and typological work on grammatical relations.  


 
\section{Valence} 
\label{valence-sec}
In LFG a lexical predicator such as a verb selects its complements via f-structure rather than c-structure.  A transitive verb selects a SUBJ and OBJ, which are features of f-structure, but it cannot select for the category `DP' because such part of speech categories belong only to c-structure.  For example the verb stem rule in \ref{lex}b has a PRED feature whose value contains (\up \feat{subj}), which has the effect of requiring a SUBJ function in the f-structure.    The f-structure (shown in \ref{fs1}) is built using the defining equations, as described above.  Then that f-structure is checked against any \textit{existential constraints} such as  the expression (\up \feat{subj}), which requires that the f-structure contain a SUBJ feature.  That constraint is satisfied, as shown in \ref{fs1}.  Moreover, the fact that (\up \feat{subj}) appears in the angled brackets means that it expresses a semantic role of the `rule' relation, hence the SUBJ value is required to contain a PRED feature, which is satisfied by the feature [\textsc{pred} `\textsc{lion}'] in  \ref{fs1}.  

Selection for grammatical relations instead of formal categories enables LFG to capture the  flexibility in the expression of a given grammatical relation described at the end of the previous section.  As noted there, in many languages the subject can be expressed either as an independent DP phrase as in English, or as a pronominal affix on the verb.  As long as the affix introduces a PRED feature and is designated by the grammar as filling the SUBJ relation, then it satisfies the subcategorization requirements imposed by a verb.  A more subtle example of flexible expression of grammatical functions  can be seen in English constructions where an argument can in principle take the form of either a DP (as in \ref{sick}a) or a clause (as in \ref{sick}b) (example \ref{sick} is from \cite{BATW2015a} PAGE).  

\eal 
 \label{sick}
\ex That problem, we talked about for days.

\ex  That he was sick, we talked about for days.

\ex We talked about that problem for days.

\ex *We talked about that he was sick for days.

\zl
The variant of \textit{talk} taking an \textit{about}-PP selects neither a DP nor a clausal complement, but rather an object (OBJ) of an oblique (OBL$_{about}$) function:  

\eal 
{{\it talk}\/: V}\qquad\feqs{(\up \pred) = `talk$\leftangle
(\up \feat{subj})(\up \feat{obl}_{about} \feat{obj})$'}    
\zl

\noindent
It is not the verb but the local c-structure environment that conditions the category of that argument: the canonical object position right-adjacent to \textit{about} can only house a DP, while the topic position allows either DP or clause (as seen by comparing \ref{sick}c and \ref{sick}d).  In LFG the grammatical functions such as SUBJ and OBJ represent equivalence classes across various modes of c-structure expression.  

HPSG captures this variability in the expression of arguments in essentially the same way as LFG, despite some terminological differences.  The HPSG correspondent of the LFG \textsc{subj} specification is not an HPSG \textsc{subj} valence list item, but rather the item of the \textsc{arg-st} list that the (optional) \textsc{subj}  item maps to, when it appears.  The same applies to complements.  The disjunction between DP and clausal expression of an argument is encoded in the \textsc{arg-st;} the restriction to DP (observed in examples \ref{sick}c,d) is encoded on the relevant valence list.  


\section{Head mobility} 
The lexical head of a phrase can sometimes appear in an alternative position apparently outside of what would normally be its phrasal projection.  Assuming that an English finite auxiliary verbs is the (category I) head of its (IP) clause, then that auxiliary appears outside its clause in a yes/no question:

\eal 
\label{mad}
\ex {} [$_{IP}$ she is mad].
\ex  Is   [$_{IP}$ she \gap\ mad]?
\zl
Transformational grammars capture the systematic relation between these two structures with a head-movement transformation that leaves the source IP structure intact, with a trace replacing the moved head.  The landing site of the moved clausal head is often assumed to be C, the complementizer position, as motivated by complementarity between the fronted verb and a lexical complementizer observed most strikingly in German but also found in other languages, including some English constructions such as the following:  

\eal 
\label{mad2}
\ex  I wonder whether [$_{IP}$ she is mad]. 
\ex  I wonder,  is  [$_{IP}$ she \gap\ mad]?
\ex  *I wonder whether is she mad.
\zl
In HPSG the sentences in \ref{mad} are treated as displaying two distinct structures generated by the grammar.  For example, assuming ternary branching in \ref{mad}b then the subject DP \textit{she} and predicate AP \textit{mad} would normally be assumed to be sisters of the fronted auxiliary \textit{is}.  On that analysis the structure is flattened out so that \textit{she mad} is not a constituent.  In fact for English the fronting of \textit{is} can even be seen as a consequence of that flattening:  English is a head-initial language so the two dependents \textit{she} and \textit{mad} are expected to follow their selecting head \textit{is}.  (SAG REFS)  

Although LFG is non-transformational, it can express the intuition behind the I-to-C movement analysis due to  the separation of autonomous c- and f-structures.  Recall from the above discussion of the DP in \ref{tree1} that functional heads such as determiners, auxiliaries and complementizers do not introduce new f-structures, but rather map to the same f-structure as their complement phrases.   The finite auxiliary can therefore appear in either I or C without affecting the f-structure, as we will see presently.  Recall also that c-structure nodes are optional and can be omitted as long as a well-formed f-structure is generated.  Comparing the non-terminal structures of \ref{tree3} and \ref{tree4}, the I node is omitted from the latter structure but otherwise they are identical.   

\eal 
 \label{tree3} { }
\zl
\begin{forest}
sm edges without translation
[CP
 [\csn{\updown}{C} [whether\\
 {(\up \feat{fin}) $=$ +}]]
[\csn{\updown}{IP} 
  [\csn{(\up\feat{subj}) $=$ \down}{DP} [she\\
      {(\up \feat{pred}) $=$ `\textsc{pro}'}\\ 
      {(\up \feat{pers}) $=$ 3}\\
      {(\up \feat{num}) $=$ \feat{sg}}\\
      {(\up \feat{gend}) $=$ \feat{fem}} ]]
[\csn{\updown}{I'}
    [\csn{\updown}{I} [is\\ 
    {(\up \feat{fin}) $=$ +}\\
    {(\up \feat{subj}) = \down}\\
                 {(\down \feat{pers}) $=$ 3}\\
                  {(\down \num) $=$ \feat{sg}}
                 ]]
    [\csn{\updown}{AP} [mad\\
     {(\up \feat{pred}) $=$ `mad$\langle (\up\feat{subj}) \rangle $'}]]
     ]]]
\end{forest}

\eal 
 \label{tree4} { }
\zl
\begin{forest}
sm edges without translation
[CP
 [\csn{\updown}{C} [is]]
[\csn{\updown}{IP} 
  [\csn{(\up\feat{subj}) $=$ \down}{DP} [she]]
  [\csn{\updown}{I'}
 %   [\csn{\updown}{I} [is]]
    [\csn{\updown}{AP} [mad\\
     {(\up \feat{pred}) $=$ `mad$\langle (\up\feat{subj}) \rangle $'}]] ]]]
\end{forest}

(Most of the lexical equations are omitted from \ref{tree4} for clarity.)  Given the \updown annotations, the C, I, and AP nodes (as well as IP and CP) all map to the same f-structure, namely the one shown in \ref{fs2}.  

\ea		
\label{fs2} 
{\avmoptions{center}
\begin{avm}
\[ subj &  \[ pred & `\textsc{pro}' \\ num & \textsc{sg} \\ pers & 3 \\ gen & \textsc{fem} \] \\
pred & `mad$\langle (\up\feat{subj}) \rangle $' \\
fin & $+$ \]
\end{avm}
}
\z
The C and I positions are appropriate for markers of clausal grammatical features such as finiteness ([\textsc{fin} +]), such as auxiliary verbs like is and complementizers like finite \textit{that} and infinitival \textit{for}: \textit{I said that/*for she is present} vs. \textit{I asked for/*that her to be present}.  English has a specialized class of  auxiliary verbs for marking finiteness from the C position, while in languages like German all finite verbs, including main verbs, can appear in a C position that is unoccupied by a lexical complementizer.  
Summarizing, the LFG framework enables a theory of head mobility based on the intuition that a clause has multiple head positions where inflectional features of the clause are encoded.  

\section{Case, agreement, and constraining equations} 
The basic theory of agreement is the same in LFG and HPSG (see \crossrefchapteralt{agreement}):  agreement occurs when 
multiple feature sets
 arising from distinct elements of a sentence specify information about a single abstract object, so that the information must be mutually consistent \citep{Kay:1984}.  
The two forms are said to agree when the values imposed by the two constraints are compatible, while ungrammaticality results when they are incompatible.  An LFG example is seen in (\ref{tree1}), where the noun, determiner and verbal suffix each specify person and/or number features of the same \subj{} value.   

The basic mechanism for case marking works in essentially the same way as agreement, in both frameworks: in case marking, distinct elements of a sentence specify case information about a single abstract object, hence that information must be compatible.   To account for the contrast in \ref{case}a, nominative \feat{case} equations are associated with the pronoun \textit{she} and added to the entry for the verbal agreement suffix \textit{-s}:

\eal 
 \label{case}
\ex She/*Her/*You rules.
\ex {\makebox[4em][l]{-{\it she}\/: {\it Pron}}\qquad\feqs{
				(\up \feat{case}) = \feat{nom}\\
                  (\up \feat{pers}) = 3\\
                  (\up \feat{num}) = \feat{sg}\\ 
                  (\up \feat{gend}) = \feat{fem}} }
\ex {\makebox[4em][l]{{\it her}\/: {\it Pron}}\qquad\feqs{
				(\up \feat{case}) = \feat{acc}\\
                  (\up \feat{pers}) = 3\\
                  (\up \feat{num}) = \feat{sg} \\
                  (\up \feat{gend}) = \feat{fem}}}
\ex {\makebox[4em][l]{-{\it s}\/: {\it infl}}\qquad\feqs{
				(\up \feat{tense}) = \feat{pres}\\
                  (\up \feat{subj}) = \down\\
                  \qquad(\down\ \feat{pers}) = 3\\
                  \qquad(\down\ \num) = \feat{sg}\\
                  \qquad(\down\ \case) = \feat{nom} }}
 \zl
The variant of \ref{case}a with \textit{her} as subject is ruled out due to a clash of \feat{case} features within the value of \subj{} in the f-structure.  The variant with you as subject is ruled out due to a clash of \feat{pers} features.  This mechanism is essentially the same as in HPSG, where it operates via the VALENCE feature.  

This account allows for underspecification of both the case assigner and the case bearing element, and of both the controller and target of agreement.   In  English, for example, gender is marked on some pronouns but not on a verbal affix; and case is marked on the verbal affix but not on  nominals, with the exception of the pronouns.  But certain case and agreement phenomena do not tolerate underspecification, and for those phenomena LFG offers an account using a \textit{constraining equation}, a mechanism absent from HPSG and indeed ruled out by current principles of HPSG theory.  (Some early precursors to HPSG included a special feature value called \feat{any} that functioned much like an LFG constraining equation \citep[pp. 36-7]{Shieber86a}, but that device has been eliminated from HPSG.)  The functional equations described so far in this chapter function by building the f-structure, as illustrated in \ref{tree1} and \ref{fs1} above; such equations are called \textit{defining equations}.  A constraining equation has the same syntax as a defining equation, but it functions by checking the completed f-structure for the presence of a feature.  An f-structure lacking the feature designated by the constraining equation is ill-formed.  

The following lexical entry for \textit{she} is identical to the one in \ref{case}b above, except that the \feat{case} equation has been replaced with a constraining equation, notated with $=_c$.  

\ea
\label{constrain}
{\makebox[4em][l]{{\it she}\/: {\it Pron}}\qquad\feqs{
				(\up \feat{case}) $=_c$ \feat{nom}\\
                  (\up \feat{pers}) = 3\\
                  (\up \feat{num}) = \feat{sg}\\ 
                  (\up \feat{gend}) = \feat{fem}} }
\z
The f-structure is built from the defining equations, after which the \subj{} field is checked for the presence of the [\feat{case} \feat{nom}] feature, as indicated by the constraining equation.  If this feature has been contributed by the finite verb, as in \ref{case}, then the sentence is predicted to be grammatical; if there is no finite verb (and there is no other source of nominative case) then it is ruled out.  This predicts the following grammaticality pattern:

\eal  Who won the popular vote in the 2016 election? \\
\label{she}
\ex {She did!  / *Her did!}
\ex {*She! / Her!}
\zl
English nominative pronouns require the presence of a finite verb, here the finite auxiliary \textit{did}.  Constraining equations operate as output filters on f-structures and are the primary way to grammatically specify the obligatoriness of a form, especially under the assumption that all daughter nodes are optional in the phrase structure.  As described in Section \ref{valence-sec} above, obligatory dependents are specified in the lexical form of a predicator using existential constraints like (\up \subj) or (\up \obj).  These are equivalent to constraining equations in which the particular value is unspecified, but some value must appear in order for the f-structure to be well-formed.  

A constraining equation for case  introduced by the case-\textit{assigner} rather than the case-bearing element, predicts that the appropriate case-bearing element must appear.  A striking example from Serbo-Croatian is described by \citet[p. 134]{WZ2003a}, who give this descriptive generalization:

\ea
{\label{dat-inst}
Serbian/Croatian Dative/Instrumental Case 
Realization\\ Condition.\medskip

If a verb or noun assigns dative or instrumental case to an NP, then that case must be morphologically realized by some element within the NP.}
\z

In Serbo-Croatian most common nouns, proper nouns, adjectives, and determiners are inflected for case.  An NP in a dative position must contain at least one such item morphologically inflected for dative case, and similarly for instrumental case.  The verb {\it pokloniti} `give' governs a dative object, such as \textit{ovom  studentu} in \ref{pokloniti}a.  But a quantified NP like \textit{ovih pet studenata} `these five students' is marked for invariant genitive case, and can appear in any case position--- except when it fails to satisfy the condition in \ref{dat-inst}, such as this dative position \citep[p. 125]{WZ2003a}:

\begin{exe} 
\ex	\label{pokloniti}
\begin{xlist}
\ex[ ]{ 		\gll  pokloniti  knjige  ovom  studentu \\
give.{\sc inf}  books.{\sc acc}  this.{\sc dat.sg}  student.{\sc dat.sg} \\
\glt `to give books to this student'}
\ex[*] {  \gll {pokloniti}  knjige  [ovih  pet  studenata] \\
give.{\sc inf}  books.{\sc acc}  this.{\sc gen.pl}  five  student.{\sc gen.pl} \\
\glt (`to give books to these five students')}
\end{xlist}
\end{exe}

\noindent
Similarly, certain foreign names such as \textit{Miki} and loanwords such as {\it braon} `brown, brunette' are undeclinable, and can appear in any case position, except those ruled out by \ref{dat-inst}.  Thus the
dative example in (\ref{admireMiki})a is unacceptable unless the inflected possessive
adjective {\it mojoj/mojom} `my'  appears.   When the possessive adjective realizes the case
feature, it is acceptable.  In  (\ref{admireMiki})b we contrast the undeclined loan word {\it
braon} `brown' with the inflected form {\it lepoj} `beautiful'.  The example is acceptable only
with the inflected adjective \citep[p. 134]{WZ2003a}.


\begin{exe} 
\ex	\label{admireMiki}
\begin{xlist}
\ex 	{\gll  Divim  se  *(mojoj)  Miki. \\
admire.{\sc 1sg}  {\sc refl}  my.{\sc dat.sg}  Miki \\
\glt `I admire (my) Miki.'}
\ex[ ] {  \gll Divim  se  {*braon/ lepoj}  Miki. \\
admire.1sg  {\sc refl}  {brown/ beautiful.{\sc dat.sg}}  Miki \\
\glt (`I admire {brunette/ beautiful} Miki')}
\end{xlist}
\end{exe}

\noindent
This complex distribution is captured simply by positing that the dative (and instrumental) case assigning equation on verbs and nouns, such as the verbs \textit{pokloniti} and \textit{divim} in the above examples, is a constraining equation:

\ea
(\up \feat{obl}$_{dat}$ \feat{case}) =$_c$ \feat{dat}
\z
Any item in dative form within the NP, such as \textit{ovom} or \textit{studentu} in (\ref{pokloniti})a or \textit{mojoj} or \textit{lepoj} in (\ref{admireMiki}), could introduce the [\feat{case} \feat{dat}] feature that satisfies this equation, but if none appears then the sentence fails.  In contrast, other case-assigning equations (e.g. for nominative, accusative, or genitive case, or for cases assigned by prepositions) are defining equations, which therefore allow the undeclined NPs to appear.  

\section{Agreement and affixal pronouns}

Agreement inflections that include the person feature derive historically from incorporated pronominal affixes.  

 \begin{exe} 
\ex	\label{bees}
\begin{xlist}
\ex 	{\gll Nj\^{u}chi   zi-n\'a-\emph{w\'a}-lum-a  a-lenje. \\
 10.bee 10.\textsc{sm}-\textsc{pst}-2.\textsc{om}-bite-\textsc{fv} 2-hunter \\
\glt `The bees bit them, the hunters.' }
 \end{xlist}
\end{exe}

(Chichewa; Bresnan and Mchombo 1987)
Bresnan and Mchombo argue that
(i) the Chichewa object marker (OM) is an incorporated pronoun;
(ii) the subject marker (SM) alternates: can be agreement marker, with an associated subject NP (njûchi ‘bees’ in (2)), or an incorporated pronoun, when no subject NP appears.
                  
\section{Lexical mapping}

\section{Long distance dependencies}

\section{Control and raising}

\section{Anaphoric binding}

\section{Semantics}

\section{Conclusion}

%Introduction:  high level differences
%Phrase structure and heads in the 2 theories
%Valence: F-structure vs ARG-ST
%Functional heads; head mobility
%Pronouns and agreement (PRED feature)
%Linking: LMT versus inheritance hierarchies
%Long distance dependencies (SLASH versus f-structure)
%Control and raising (Locality is easier to account for in HPSG)
%Anaphoric binding, yawn.
%Semantics:  Glue (vs MRS?)
%Conclusion
 
\section*{Abbreviations}
\section*{Acknowledgements}

\printbibliography[heading=subbibliography,notkeyword=this] 
\end{document}
